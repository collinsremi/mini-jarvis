{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb427a5-24e6-4bca-b42b-3f330966a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304d50b6-636e-4533-8480-f9aa72cdf02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from dotenv import load_dotenv\n",
    "from elevenlabs.client import ElevenLabs\n",
    "from elevenlabs import play\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "with open(\"my words.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text_input = f.read().strip()\n",
    "\n",
    "print(\"ðŸ“„ Text loaded from file:\\n\", text_input)\n",
    "\n",
    "elevenlabs = ElevenLabs(\n",
    "  api_key=os.getenv(\"ELEVEN_API_KEY\"),\n",
    ")\n",
    "\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model = \"gemini-1.5-flash\")\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(llm = llm, memory= memory)\n",
    "\n",
    "responce1 = conversation.invoke(text_input)[\"response\"]\n",
    "\n",
    "audio = elevenlabs.text_to_speech.convert(\n",
    "    text= responce1,\n",
    "    voice_id=\"JBFqnCBsd6RMkjVDRZzb\",\n",
    "    model_id=\"eleven_multilingual_v2\",\n",
    "    output_format=\"mp3_44100_128\",\n",
    ")\n",
    "\n",
    "# Join all chunks into bytes\n",
    "audio_bytes = b\"\".join(audio)\n",
    "\n",
    "# Save to file\n",
    "with open(\"output2.mp3\", \"wb\") as f:\n",
    "    f.write(audio_bytes)\n",
    "\n",
    "print(\"Audio saved as output.mp3\")\n",
    "\n",
    "# Load a pre-trained Whisper model (tiny is fastest for CPU)\n",
    "model = whisper.load_model(\"tiny\")  \n",
    "\n",
    "# Transcribe an audio file\n",
    "result = model.transcribe(\"output2.mp3\")\n",
    "print(\"Detected text:\", result[\"text\"])\n",
    "print(\"Detected language:\", result[\"language\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5820e206-2faf-4160-8650-d5734db55067",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(audio_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d559c396-9727-4f6f-8904-8fbf4944c187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
